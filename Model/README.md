## 模型設定說明
本模型主要採用了 CatBoost 進行訓練，相關參數設置以及概念如下：

- **iterations**：模型的訓練迭代次數。
- **learning_rate (0.0225)**：學習速率，也稱為步長或學習率。它決定了每個樹對最終結果的影響。較小的值意味著需要更多的樹來訓練模型，但通常可以提高模型的質量。
- **depth (8)**：決策樹的深度。數值越大，模型就越複雜，但計算成本和過擬合的風險也越高。
- **loss_function ('Logloss')**：'Logloss' 對於二分類問題常用的損失函數。
- **eval_metric ('F1')**：用於模型評估的度量標準。
- **early_stopping_rounds (800)**：如果經過指定的迭代次數後，評估指標沒有改善，則提前停止訓練。
- **verbose (100)**：這裡設置為每100次迭代輸出一次訓練過程。
- **l2_leaf_reg (3)**：L2 正則化項對葉權重的係數。這有助於防止模型過擬合。
- **leaf_estimation_iterations (10)**：在梯度提升過程中用於葉子估計的迭代次數。
- **max_ctr_complexity (10)**：用於類別特徵組合的最大複雜度。
- **task_type ('GPU')**：在這裡設置為 'GPU' 表示使用 GPU 進行訓練，這通常比 CPU 快。
- **scale_pos_weight (9.245)**：用於不平衡數據集的正例權重。這有助於在存在類別不平衡時平衡正負樣本的影響。調參測試認為 8-10 之間都有不錯的效果。
- **grow_policy ('Lossguide')**：決定樹的生長策略。'Lossguide' 表示基於損失函數的樹生長策略。

### Lossguide 策略的特點
- **基於損失的節點分裂**：在 Lossguide 策略中，節點的分裂是根據損失減少（loss reduction）來指導的。
- **更有效的資源利用**：相對於傳統的深度優先生長策略（例如，先使樹盡可能深地生長），Lossguide 策略通常更高效，因為它專注於最有潛力減少損失的節點，從而更好地利用計算資源。
- **適合大規模數據集**：由於其高效的節點分裂機制，Lossguide 策略特別適用於大規模數據集，因為它可以減少不必要的計算，並專注於最重要的節點分裂。
- **減少過擬合的風險**：這種策略通過避免過度生長樹的深度，有助於減少過擬合的風險。

## 備註
因最後一次上傳資料未使用 setseed，以及後半段在超參數部分都有些許調整小數點值並未記錄確實，貴單位在測試的結果上可能會與最後一次上傳結果有一點點誤差，
但參數的設置皆未更動，僅針對數值有些許更動。對於此次缺失感到非常抱歉。
