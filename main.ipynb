{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4300ee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import auc\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from catboost import CatBoostClassifier, Pool, EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from scipy.stats import entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd27f51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train = pd.read_csv('dataset_1st/training.csv')\n",
    "new_train = pd.read_csv('dataset_2nd/public.csv')\n",
    "\n",
    "old_val = pd.read_csv('dataset_1st/public_processed.csv')\n",
    "new_val = pd.read_csv('dataset_2nd/private_1_processed.csv')\n",
    "\n",
    "example = pd.read_csv('dataset_1st/31_範例繳交檔案.csv')\n",
    "\n",
    "df = pd.concat([old_train, new_train, new_val],sort=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8486324e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dabef9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 計算交易活動，計算特定卡在前30天消費所佔的次數比率與之後的比率，計算之間的變化率\n",
    "\n",
    "# 計算每張卡在其持有者所有交易中的活動次數\n",
    "card_activity_count = df_copy.groupby(['chid', 'cano'])['txkey'].count()\n",
    "card_activity_count = card_activity_count.rename('card_transaction_count').reset_index()\n",
    "df_copy = df_copy.merge(card_activity_count, on=['chid', 'cano'], how='left')\n",
    "\n",
    "# 計算每個持卡人的總交易次數\n",
    "customer_total_transactions = df_copy.groupby('chid')['txkey'].count()\n",
    "customer_total_transactions = customer_total_transactions.rename('customer_total_transactions').reset_index()\n",
    "\n",
    "# 將每個持卡人的總交易次數合併到主資料集\n",
    "df_copy = df_copy.merge(customer_total_transactions, on='chid', how='left')\n",
    "\n",
    "# 篩選前30天的交易數據\n",
    "df_copy_before_30 = df_copy[df_copy['locdt'] <= 30]\n",
    "\n",
    "# 計算前30天的交易比例\n",
    "card_activity_before_30 = df_copy_before_30.groupby(['chid', 'cano'])['txkey'].count().reset_index()\n",
    "total_transactions_before_30 = df_copy_before_30.groupby('chid')['txkey'].count().reset_index()\n",
    "card_ratio_before_30 = card_activity_before_30.merge(total_transactions_before_30, on='chid')\n",
    "card_ratio_before_30['card_transaction_ratio_before_30'] = card_ratio_before_30['txkey_x'] / card_ratio_before_30['txkey_y']\n",
    "\n",
    "# 篩選後30天的交易數據\n",
    "df_copy_after_30 = df_copy[df_copy['locdt'] > 30]\n",
    "\n",
    "# 計算後30天的交易比例\n",
    "card_activity_after_30 = df_copy_after_30.groupby(['chid', 'cano'])['txkey'].count().reset_index()\n",
    "total_transactions_after_30 = df_copy_after_30.groupby('chid')['txkey'].count().reset_index()\n",
    "card_ratio_after_30 = card_activity_after_30.merge(total_transactions_after_30, on='chid')\n",
    "card_ratio_after_30['card_transaction_ratio_after_30'] = card_ratio_after_30['txkey_x'] / card_ratio_after_30['txkey_y']\n",
    "\n",
    "# 計算前後30天的比例變化率\n",
    "card_ratio_change = card_ratio_before_30.merge(card_ratio_after_30, on=['chid', 'cano'])\n",
    "card_ratio_change['ratio_change'] = (card_ratio_change['card_transaction_ratio_after_30'] - card_ratio_change['card_transaction_ratio_before_30']) / card_ratio_change['card_transaction_ratio_before_30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "220a42c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已經計算好的 card_ratio_before_30, card_ratio_after_30, 和 card_ratio_change\n",
    "\n",
    "# 將重要的欄位合併到 df_copy\n",
    "df_copy = df_copy.merge(card_ratio_before_30[['chid', 'cano', 'card_transaction_ratio_before_30']], on=['chid', 'cano'], how='left')\n",
    "df_copy = df_copy.merge(card_ratio_after_30[['chid', 'cano', 'card_transaction_ratio_after_30']], on=['chid', 'cano'], how='left')\n",
    "df_copy = df_copy.merge(card_ratio_change[['chid', 'cano', 'ratio_change']], on=['chid', 'cano'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfcb92f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 計算每個卡號每天的交易頻率並進行正規化處理\n",
    "\n",
    "transactions_per_day = df_copy.groupby(['cano', 'locdt']).size().reset_index(name='daily_transactions')\n",
    "\n",
    "# 計算最大最小值\n",
    "\n",
    "min_max_transactions = transactions_per_day.groupby('cano')['daily_transactions'].agg(['min', 'max']).reset_index()\n",
    "min_max_transactions.columns = ['cano', 'min_daily_trans', 'max_daily_trans']\n",
    "df_copy = df_copy.merge(min_max_transactions, on='cano', how='left')\n",
    "\n",
    "# 正規化\n",
    "\n",
    "df_copy = df_copy.merge(transactions_per_day, on=['cano', 'locdt'], how='left')\n",
    "df_copy['normalized_trans_freq'] = df_copy.apply(lambda x: (x['daily_transactions'] - x['min_daily_trans']) / (x['max_daily_trans'] - x['min_daily_trans']) if x['max_daily_trans'] != x['min_daily_trans'] else 0, axis=1)\n",
    "\n",
    "# fill na\n",
    "df_copy['normalized_trans_freq'] = df_copy['normalized_trans_freq'].fillna(-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c02e2762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 計算每個卡號每天的交易金額並進行正規化處理\n",
    "\n",
    "daily_amount_sum = df_copy.groupby(['cano', 'locdt'])['conam'].sum().reset_index(name='daily_amount_sum')\n",
    "\n",
    "# 計算最大最小值\n",
    "\n",
    "min_max_daily_amount = daily_amount_sum.groupby('cano')['daily_amount_sum'].agg(['min', 'max']).reset_index()\n",
    "min_max_daily_amount.columns = ['cano', 'min_daily_amount', 'max_daily_amount']\n",
    "daily_amount_sum = daily_amount_sum.merge(min_max_daily_amount, on='cano', how='left')\n",
    "\n",
    "# 正規化\n",
    "\n",
    "daily_amount_sum['normalized_daily_amount'] = daily_amount_sum.apply(\n",
    "    lambda x: (x['daily_amount_sum'] - x['min_daily_amount']) / (x['max_daily_amount'] - x['min_daily_amount']) \n",
    "    if x['max_daily_amount'] != x['min_daily_amount'] else 0, \n",
    "    axis=1)\n",
    "\n",
    "df_copy = df_copy.merge(daily_amount_sum[['cano', 'locdt', 'normalized_daily_amount']], on=['cano', 'locdt'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e991f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txkey</th>\n",
       "      <th>locdt</th>\n",
       "      <th>loctm</th>\n",
       "      <th>chid</th>\n",
       "      <th>cano</th>\n",
       "      <th>contp</th>\n",
       "      <th>etymd</th>\n",
       "      <th>mchno</th>\n",
       "      <th>acqic</th>\n",
       "      <th>mcc</th>\n",
       "      <th>...</th>\n",
       "      <th>customer_total_transactions</th>\n",
       "      <th>card_transaction_ratio_before_30</th>\n",
       "      <th>card_transaction_ratio_after_30</th>\n",
       "      <th>ratio_change</th>\n",
       "      <th>min_daily_trans</th>\n",
       "      <th>max_daily_trans</th>\n",
       "      <th>daily_transactions</th>\n",
       "      <th>normalized_trans_freq</th>\n",
       "      <th>normalized_daily_amount</th>\n",
       "      <th>difference_seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1c09727c939eb69ead2a4ce4072b8aa18992a64f01fcb4...</td>\n",
       "      <td>46</td>\n",
       "      <td>10:18:12</td>\n",
       "      <td>84d2dc85d4da6a7fa284a11a4290d7e9a969163dcb4d82...</td>\n",
       "      <td>3dd5bf1e29e5e0baa789ce692fe5dbd34ff05173acf351...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cad752c5d05d2bdcc30d64fa4e68404c2d1f7be5d14d52...</td>\n",
       "      <td>8f6b3ff512a001e0d1988c6cd888ef8c74112fb71117e5...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.063434</td>\n",
       "      <td>76186.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2043f245a93bc6328dac964d6dbc89f13a0346062c194d...</td>\n",
       "      <td>17</td>\n",
       "      <td>08:55:09</td>\n",
       "      <td>9a8cf5d0afd729cb7876f6b3172152c7c9c6fabd40515c...</td>\n",
       "      <td>8cb13f9b38c7bbc02d210e580dcbbcbb6c95bf18bc3320...</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4356c6642ef6e837543b577c7ee3ffa92b4b8fcfb57254...</td>\n",
       "      <td>379166ff4a62dac343b4b734188aa618716cc496e48b65...</td>\n",
       "      <td>282.0</td>\n",
       "      <td>...</td>\n",
       "      <td>59</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>-0.221453</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028906</td>\n",
       "      <td>234123.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>e4853710290a8409279f3279f8032ae670824bd19aa173...</td>\n",
       "      <td>44</td>\n",
       "      <td>21:26:41</td>\n",
       "      <td>dcc1389a5765d6f53152cf85970fbe78a83fd3d1c299b0...</td>\n",
       "      <td>1ec32868e5e1d5ff8df56737c2a91326cbfe3364382de6...</td>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5b7eff061f8896aac4339ea35c25f8bb956a43bc486460...</td>\n",
       "      <td>8f6b3ff512a001e0d1988c6cd888ef8c74112fb71117e5...</td>\n",
       "      <td>288.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>690457.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74d811b1dbc28b22b73ba2c79bb6033791d913b6d27a25...</td>\n",
       "      <td>42</td>\n",
       "      <td>10:27:02</td>\n",
       "      <td>577f2329d1eccd59ba0abaf6113bb78dcd575badcbc57f...</td>\n",
       "      <td>4359dca1ac6a835eceb2bc0dd6b0b710f030c3499126e9...</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>cad752c5d05d2bdcc30d64fa4e68404c2d1f7be5d14d52...</td>\n",
       "      <td>36684976be1f529e6e2a32c9edab4cf8e364b2b916ae2c...</td>\n",
       "      <td>375.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.867846</td>\n",
       "      <td>948553.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>68ca182343969d429d79a34e532bc1ca7a3cc032c2ad81...</td>\n",
       "      <td>31</td>\n",
       "      <td>18:57:37</td>\n",
       "      <td>fff6b4126c40620b1fbb11d4de02cd67b9e95071caa40b...</td>\n",
       "      <td>a3837f2905383f235a72679482c5f02e40f2a8ca29750d...</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50d5b02ce3fc88723438c2a29cfdb04be4a1a11280ddb6...</td>\n",
       "      <td>379166ff4a62dac343b4b734188aa618716cc496e48b65...</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.478636</td>\n",
       "      <td>6997.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               txkey  locdt     loctm  \\\n",
       "0  1c09727c939eb69ead2a4ce4072b8aa18992a64f01fcb4...     46  10:18:12   \n",
       "1  2043f245a93bc6328dac964d6dbc89f13a0346062c194d...     17  08:55:09   \n",
       "2  e4853710290a8409279f3279f8032ae670824bd19aa173...     44  21:26:41   \n",
       "3  74d811b1dbc28b22b73ba2c79bb6033791d913b6d27a25...     42  10:27:02   \n",
       "4  68ca182343969d429d79a34e532bc1ca7a3cc032c2ad81...     31  18:57:37   \n",
       "\n",
       "                                                chid  \\\n",
       "0  84d2dc85d4da6a7fa284a11a4290d7e9a969163dcb4d82...   \n",
       "1  9a8cf5d0afd729cb7876f6b3172152c7c9c6fabd40515c...   \n",
       "2  dcc1389a5765d6f53152cf85970fbe78a83fd3d1c299b0...   \n",
       "3  577f2329d1eccd59ba0abaf6113bb78dcd575badcbc57f...   \n",
       "4  fff6b4126c40620b1fbb11d4de02cd67b9e95071caa40b...   \n",
       "\n",
       "                                                cano  contp  etymd  \\\n",
       "0  3dd5bf1e29e5e0baa789ce692fe5dbd34ff05173acf351...      5    1.0   \n",
       "1  8cb13f9b38c7bbc02d210e580dcbbcbb6c95bf18bc3320...      5    8.0   \n",
       "2  1ec32868e5e1d5ff8df56737c2a91326cbfe3364382de6...      5    4.0   \n",
       "3  4359dca1ac6a835eceb2bc0dd6b0b710f030c3499126e9...      5    1.0   \n",
       "4  a3837f2905383f235a72679482c5f02e40f2a8ca29750d...      5    5.0   \n",
       "\n",
       "                                               mchno  \\\n",
       "0  cad752c5d05d2bdcc30d64fa4e68404c2d1f7be5d14d52...   \n",
       "1  4356c6642ef6e837543b577c7ee3ffa92b4b8fcfb57254...   \n",
       "2  5b7eff061f8896aac4339ea35c25f8bb956a43bc486460...   \n",
       "3  cad752c5d05d2bdcc30d64fa4e68404c2d1f7be5d14d52...   \n",
       "4  50d5b02ce3fc88723438c2a29cfdb04be4a1a11280ddb6...   \n",
       "\n",
       "                                               acqic    mcc  ...  \\\n",
       "0  8f6b3ff512a001e0d1988c6cd888ef8c74112fb71117e5...  375.0  ...   \n",
       "1  379166ff4a62dac343b4b734188aa618716cc496e48b65...  282.0  ...   \n",
       "2  8f6b3ff512a001e0d1988c6cd888ef8c74112fb71117e5...  288.0  ...   \n",
       "3  36684976be1f529e6e2a32c9edab4cf8e364b2b916ae2c...  375.0  ...   \n",
       "4  379166ff4a62dac343b4b734188aa618716cc496e48b65...  406.0  ...   \n",
       "\n",
       "   customer_total_transactions  card_transaction_ratio_before_30  \\\n",
       "0                           74                              1.00   \n",
       "1                           59                              0.68   \n",
       "2                           14                              1.00   \n",
       "3                            6                              1.00   \n",
       "4                           64                              1.00   \n",
       "\n",
       "   card_transaction_ratio_after_30  ratio_change  min_daily_trans  \\\n",
       "0                         1.000000      0.000000                1   \n",
       "1                         0.529412     -0.221453                1   \n",
       "2                         1.000000      0.000000                1   \n",
       "3                         1.000000      0.000000                1   \n",
       "4                         1.000000      0.000000                1   \n",
       "\n",
       "   max_daily_trans  daily_transactions  normalized_trans_freq  \\\n",
       "0                5                   1                    0.0   \n",
       "1                3                   3                    1.0   \n",
       "2                1                   1                    0.0   \n",
       "3                1                   1                    0.0   \n",
       "4                6                   3                    0.4   \n",
       "\n",
       "   normalized_daily_amount  difference_seconds  \n",
       "0                 0.063434             76186.0  \n",
       "1                 0.028906            234123.0  \n",
       "2                 0.005210            690457.0  \n",
       "3                 0.867846            948553.0  \n",
       "4                 0.478636              6997.0  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 計算上次刷卡時間(秒數)\n",
    "\n",
    "def impute_time_zero(x):\n",
    "    x = str(int(x)).zfill(6)\n",
    "    return datetime.datetime.strptime(x, \"%H%M%S\").time()\n",
    "\n",
    "df_copy['loctm'] = df_copy['loctm'].apply(impute_time_zero)\n",
    "\n",
    "sorted_df = df_copy.sort_values(by=['cano', 'locdt', 'loctm'])\n",
    "\n",
    "sorted_df['prev_locdt'] = sorted_df.groupby('cano')['locdt'].shift(1)\n",
    "sorted_df['prev_loctm'] = sorted_df.groupby('cano')['loctm'].shift(1)\n",
    "\n",
    "sorted_df['loctm_seconds'] = sorted_df['loctm'].apply(lambda x: x.hour * 3600 + x.minute * 60 + x.second)\n",
    "sorted_df['prev_loctm_seconds'] = sorted_df['prev_loctm'].apply(\n",
    "    lambda x: x.hour * 3600 + x.minute * 60 + x.second if pd.notnull(x) else 0)\n",
    "\n",
    "sorted_df['difference_seconds'] = (sorted_df['locdt'] - sorted_df['prev_locdt']) * 86400 + \\\n",
    "                                  (sorted_df['loctm_seconds'] - sorted_df['prev_loctm_seconds'])\n",
    "\n",
    "sorted_df['difference_seconds'] = sorted_df['difference_seconds'].fillna(-1)\n",
    "\n",
    "df_copy = df_copy.merge(sorted_df[['txkey', 'difference_seconds']], on='txkey', how='left')\n",
    "\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d51bba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5 計算每個卡號刷卡的每筆之間的時間間隔的平均和標準差\n",
    "\n",
    "def calculate_transaction_intervals(group):\n",
    "    \"\"\"\n",
    "    計算信用卡交易時間間隔的平均值和標準差。\n",
    "\n",
    "    :param group: Grouped DataFrame by 'cano'.\n",
    "    :return: Tuple with average and standard deviation of transaction intervals in seconds.\n",
    "    \"\"\"\n",
    "    # 計算日期差異（秒）和時間差異\n",
    "    date_diffs = group['locdt'].diff().fillna(0) * 86400\n",
    "    time_diffs = group['loctm_seconds'].diff().fillna(0)\n",
    "\n",
    "    # 總時間差異\n",
    "    total_diffs = date_diffs + time_diffs\n",
    "\n",
    "    # 排除第一筆交易\n",
    "    total_diffs = total_diffs[1:]\n",
    "\n",
    "    # 計算平均值和標準差\n",
    "    avg_interval = total_diffs.mean() if not total_diffs.empty else -1\n",
    "    std_interval = total_diffs.std() if not total_diffs.empty else -1\n",
    "\n",
    "    return avg_interval, std_interval\n",
    "\n",
    "# 應用函數並創建新的 DataFrame\n",
    "intervals_df = sorted_df.groupby('cano').apply(calculate_transaction_intervals)\n",
    "intervals_df = pd.DataFrame(intervals_df.tolist(), index=intervals_df.index).reset_index()\n",
    "intervals_df.columns = ['cano', 'avg_interval', 'std_interval']\n",
    "\n",
    "# 合併到原始 DataFrame\n",
    "df_copy = df_copy.merge(intervals_df, on='cano', how='left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78c0809f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 6 每張卡號在不同商品類別（mcc）下的交易情況\n",
    "\n",
    "# 一次計算所有統計數據\n",
    "grouped = df_copy.groupby(['cano', 'mcc'])\n",
    "\n",
    "# 創建一個新的數據框來存儲結果\n",
    "stats = pd.DataFrame({\n",
    "    'transactions_per_mcc': grouped['txkey'].count(),\n",
    "    'mcc_total_amount': grouped['conam'].sum(),\n",
    "    'variance_transaction_amount_per_mcc': grouped['conam'].var()\n",
    "})\n",
    "\n",
    "# 計算MAD\n",
    "def mad(series):\n",
    "    return (series - series.median()).abs().median()\n",
    "\n",
    "stats['mad_transaction_amount_per_mcc'] = grouped['conam'].apply(mad)\n",
    "\n",
    "# 重置索引以便後續合併\n",
    "stats.reset_index(inplace=True)\n",
    "\n",
    "# 合併計算結果回原始數據框\n",
    "df_copy = df_copy.merge(stats, on=['cano', 'mcc'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea74e709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: 分析每張卡號在不同 mchno下的交易情況\n",
    "\n",
    "# 一次計算所有統計數據\n",
    "grouped = df_copy.groupby(['cano', 'mchno'])\n",
    "\n",
    "# 創建一個新的數據框來存儲結果\n",
    "stats = pd.DataFrame({\n",
    "    'transactions_per_mchno': grouped['txkey'].count(),\n",
    "    'mchno_total_amount': grouped['conam'].sum(),\n",
    "    'variance_transaction_amount_per_mchno': grouped['conam'].var()\n",
    "})\n",
    "\n",
    "# 計算MAD\n",
    "stats['mad_transaction_amount_per_mchno'] = grouped['conam'].apply(mad)\n",
    "\n",
    "# 重置索引以便後續合併\n",
    "stats.reset_index(inplace=True)\n",
    "\n",
    "# 合併計算結果回原始數據框\n",
    "df_copy = df_copy.merge(stats, on=['cano', 'mchno'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a890b5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 觀察交易地點變化\n",
    "\n",
    "df_copy = df_copy.sort_values(by=['cano', 'locdt'])\n",
    "\n",
    "# initialize \n",
    "df_copy['city_change'] = 0\n",
    "df_copy['country_change'] = 0  \n",
    "\n",
    "previous_locations = df_copy.groupby('cano')[['scity', 'stocn']].shift()\n",
    "\n",
    "# 判斷卡號是否相同\n",
    "df_copy['same_cano'] = df_copy['cano'] == df_copy['cano'].shift()\n",
    "\n",
    "# 若支付城市改變則標註為 1\n",
    "df_copy['city_change'] = ((df_copy['scity'] != previous_locations['scity']) & df_copy['same_cano']).astype(int)\n",
    "\n",
    "# 若支付國家改變則標註為 1\n",
    "df_copy['country_change'] = ((df_copy['stocn'] != previous_locations['stocn']) & df_copy['same_cano']).astype(int)\n",
    "\n",
    "df_copy.drop(columns=['same_cano'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "000fca96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9 把loctom拆成鐘點 \n",
    "\n",
    "def time_to_seconds(t):\n",
    "    return t.hour * 3600 + t.minute * 60 + t.second\n",
    "\n",
    "def time_to_hour(t):\n",
    "    return t.hour\n",
    "\n",
    "def time_to_string(t):\n",
    "    return t.strftime(\"%H%M%S\")\n",
    "\n",
    "df_copy['hour'] = df_copy['loctm'].apply(time_to_hour)\n",
    "df_copy['loctm_seconds'] = df_copy['loctm'].apply(time_to_seconds)\n",
    "df_copy['loctm'] = df_copy['loctm'].apply(time_to_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e176fd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.concat([old_train,new_train],sort=False)\n",
    "new_train_data = df_copy.merge(train_data[['txkey']], on='txkey', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cd516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['label', 'txkey', 'chid', 'cano', 'bnsfg', 'flbmk', 'ovrlt', 'iterm']\n",
    "\n",
    "cat_features = ['contp', 'etymd', 'mcc', 'ecfg', 'stocn', 'scity', 'insfg', 'mchno', 'acqic',\n",
    "                'stscd', 'hcefg', 'csmcu', 'flg_3dsmk', 'hour','city_change', 'country_change']\n",
    "\n",
    "# 從數據框中刪除指定的列\n",
    "X = new_train_data.drop(columns=columns_to_drop)\n",
    "y = new_train_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b4545a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "del old_train\n",
    "del train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aaded1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train_data.drop(columns=columns_to_drop)\n",
    "for feature in cat_features:\n",
    "    X[feature] = X[feature].astype(str)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.35, \n",
    "    random_state=40, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "train_pool = Pool(X_train, y_train,cat_features=cat_features)\n",
    "test_pool = Pool(X_test, y_test,cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32b976af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['locdt', 'loctm', 'contp', 'etymd', 'mchno', 'acqic', 'mcc', 'conam', 'ecfg', 'insfg', 'flam1', 'stocn', 'scity', 'stscd', 'hcefg', 'csmcu', 'csmam', 'flg_3dsmk', 'card_transaction_count', 'customer_total_transactions', 'card_transaction_ratio_before_30', 'card_transaction_ratio_after_30', 'ratio_change', 'min_daily_trans', 'max_daily_trans', 'daily_transactions', 'normalized_trans_freq', 'normalized_daily_amount', 'difference_seconds', 'avg_interval', 'std_interval', 'transactions_per_mcc', 'mcc_total_amount', 'variance_transaction_amount_per_mcc', 'mad_transaction_amount_per_mcc', 'transactions_per_mchno', 'mchno_total_amount', 'variance_transaction_amount_per_mchno', 'mad_transaction_amount_per_mchno', 'city_change', 'country_change', 'hour', 'loctm_seconds']\n"
     ]
    }
   ],
   "source": [
    "feature_list = X_train.columns.tolist()\n",
    "print(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c1eb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "註記：若電腦為MAC系列，則須無法使用 task_type='GPU'，可將其註解並且開啟subsample，接受另外兩個參數再進行訓練，超參數皆無須調整\n",
    "\n",
    "\"\"\"\n",
    "catboost_model = CatBoostClassifier(\n",
    "    iterations=5000,  \n",
    "    learning_rate=0.0325,\n",
    "    depth=7,\n",
    "    loss_function='Logloss',\n",
    "    eval_metric='F1',  \n",
    "    early_stopping_rounds=800,\n",
    "    random_seed=42,\n",
    "    verbose=100,\n",
    "    l2_leaf_reg=3,\n",
    "    leaf_estimation_iterations=10,\n",
    "#     colsample_bylevel=0.8,\n",
    "#     subsample=0.85,\n",
    "    max_ctr_complexity=10,\n",
    "    task_type='GPU',\n",
    "    scale_pos_weight = 9.484, # 9.45\n",
    "    random_strength=3,\n",
    "    grow_policy='Lossguide'\n",
    ")\n",
    "\n",
    "catboost_model.fit(\n",
    "    train_pool,\n",
    "    eval_set=test_pool,\n",
    "    use_best_model=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da40e4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = catboost_model.predict(test_pool)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "\n",
    "print(f\"Precision: {precision}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c08a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall = recall_score(y_test, y_pred, average='binary', pos_label=1)\n",
    "\n",
    "print(f\"Recall: {recall}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43053a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the feature names from the preprocessed dataset\n",
    "\n",
    "feature_names =['locdt', 'loctm', 'contp', 'etymd', 'mchno', 'acqic', 'mcc', \n",
    "                'conam', 'ecfg', 'insfg', 'flam1', 'stocn', 'scity', 'stscd', \n",
    "                'hcefg', 'csmcu', 'csmam', 'flg_3dsmk', 'card_transaction_count', \n",
    "                'customer_total_transactions', 'card_transaction_ratio_before_30', \n",
    "                'card_transaction_ratio_after_30', 'ratio_change', 'min_daily_trans', \n",
    "                'max_daily_trans', 'daily_transactions', 'normalized_trans_freq', \n",
    "                'normalized_daily_amount', 'difference_seconds', 'avg_interval', \n",
    "                'std_interval', 'transactions_per_mcc_x', 'mcc_total_amount_x', \n",
    "                'variance_transaction_amount_per_mcc_x', 'transactions_per_mcc_y', \n",
    "                'mcc_total_amount_y', 'variance_transaction_amount_per_mcc_y', \n",
    "                'mad_transaction_amount_per_mcc', 'transactions_per_mchno', 'mchno_total_amount', \n",
    "                'variance_transaction_amount_per_mchno', 'mad_transaction_amount_per_mchno', \n",
    "                'city_change', 'country_change', 'hour', 'loctm_seconds']\n",
    "\n",
    "feature_importances = catboost_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort the DataFrame by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the feature importance\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2215cc3",
   "metadata": {},
   "source": [
    "# 合併資料輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45251a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_val_data = df_copy.merge(example[['txkey']], on='txkey', how='inner')\n",
    "new_val_data = new_val_data.set_index('txkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e52d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['chid', 'cano', 'bnsfg', 'flbmk', 'ovrlt', 'iterm']\n",
    "\n",
    "cat_features = ['contp', 'etymd', 'mcc', 'ecfg', 'stocn', 'scity', 'insfg', 'mchno', 'acqic',\n",
    "                'stscd', 'hcefg', 'csmcu', 'flg_3dsmk', 'hour','city_change', 'country_change', 'unusual_3dsmk']\n",
    "\n",
    "X = new_val_data.drop(columns=columns_to_drop)\n",
    "\n",
    "for feature in cat_features:\n",
    "    X[feature] = X[feature].astype(str)\n",
    "    \n",
    "test_pool = Pool(X, cat_features=cat_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f25ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = catboost_model.predict(test_pool).astype(int)\n",
    "new_val_data['pred']= y_pred\n",
    "new_val_data =new_val_data.reset_index()\n",
    "\n",
    "output_df = new_val_data[['txkey', 'pred']].set_index('txkey')\n",
    "example = example.drop_duplicates(subset='txkey')\n",
    "\n",
    "df2_sorted = example[['txkey']].merge(output_df, on='txkey', how='left')\n",
    "df2_sorted = df2_sorted.set_index('txkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bedbfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'dataset_2nd/predictions_secondround.csv'\n",
    "df2_sorted.to_csv(output_filename, index='True')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
